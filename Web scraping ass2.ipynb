{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27af236",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Analyst” in “Job title, Skills” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b32376b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.15.2-py3-none-any.whl (10.2 MB)\n",
      "                                              0.0/10.2 MB ? eta -:--:--\n",
      "     -                                        0.4/10.2 MB 12.2 MB/s eta 0:00:01\n",
      "     ---                                      0.8/10.2 MB 10.0 MB/s eta 0:00:01\n",
      "     ----                                     1.2/10.2 MB 10.5 MB/s eta 0:00:01\n",
      "     ------                                   1.5/10.2 MB 9.8 MB/s eta 0:00:01\n",
      "     -------                                  2.0/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------                                2.4/10.2 MB 9.7 MB/s eta 0:00:01\n",
      "     -----------                              2.8/10.2 MB 9.5 MB/s eta 0:00:01\n",
      "     ------------                             3.2/10.2 MB 9.7 MB/s eta 0:00:01\n",
      "     --------------                           3.6/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------                          4.0/10.2 MB 9.3 MB/s eta 0:00:01\n",
      "     -----------------                        4.4/10.2 MB 9.7 MB/s eta 0:00:01\n",
      "     ------------------                       4.8/10.2 MB 9.5 MB/s eta 0:00:01\n",
      "     -------------------                      4.9/10.2 MB 9.5 MB/s eta 0:00:01\n",
      "     -------------------                      4.9/10.2 MB 9.5 MB/s eta 0:00:01\n",
      "     ----------------------                   5.7/10.2 MB 9.3 MB/s eta 0:00:01\n",
      "     ------------------------                 6.3/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "     --------------------------               6.7/10.2 MB 9.5 MB/s eta 0:00:01\n",
      "     ---------------------------              7.1/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "     -----------------------------            7.5/10.2 MB 9.5 MB/s eta 0:00:01\n",
      "     ------------------------------           7.8/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "     --------------------------------         8.2/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------        8.6/10.2 MB 9.5 MB/s eta 0:00:01\n",
      "     -----------------------------------      9.0/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "     ------------------------------------     9.4/10.2 MB 9.5 MB/s eta 0:00:01\n",
      "     --------------------------------------   9.8/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  10.2/10.2 MB 9.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 10.2/10.2 MB 9.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\viv\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.23.1-py3-none-any.whl (448 kB)\n",
      "                                              0.0/448.3 kB ? eta -:--:--\n",
      "     --------------------------------      399.4/448.3 kB 12.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 448.3/448.3 kB 7.1 MB/s eta 0:00:00\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\viv\\anaconda3\\lib\\site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\viv\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\viv\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\viv\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\viv\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\viv\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\viv\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "                                              0.0/58.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 58.3/58.3 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: sniffio, outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.15.2 sniffio-1.3.0 trio-0.23.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1483f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78ec07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.shine.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d38c4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "997055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb15c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc76fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,\"//h2[@itemprop]\")\n",
    "for i in title_tags:\n",
    "    title = i.text\n",
    "    job_titles.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffef4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Company_Name = []\n",
    "\n",
    "companies = driver.find_elements(By.CLASS_NAME,\"jobCard_jobCard_cName__mYnow\")\n",
    "for i in companies:\n",
    "    company = i.text\n",
    "    Company_Name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f58fd012",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exp_Req = []\n",
    "\n",
    "Exp_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in Exp_tags:\n",
    "    Experience = i.text\n",
    "    Exp_Req.append(Experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "058f3c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(Company_Name),len(Exp_Req))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ed3149c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB TITLES</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst Vacancy</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst Vacancy</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst Urgent Recruitment</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst Urgent Recruitment</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst Urgent Recruitment</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst 1</td>\n",
       "      <td>merck ltd</td>\n",
       "      <td>1 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analytics - Analyst</td>\n",
       "      <td>jpmorgan</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>divya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        JOB TITLES            Company Experience Required\n",
       "0             Data Analyst Vacancy  divya interprises          0 to 4 Yrs\n",
       "1             Data Analyst Vacancy  divya interprises          0 to 4 Yrs\n",
       "2            Clinical Data Analyst    quiscon biotech          0 to 2 Yrs\n",
       "3  Data Analyst Urgent Recruitment  divya interprises          0 to 4 Yrs\n",
       "4  Data Analyst Urgent Recruitment  divya interprises          0 to 4 Yrs\n",
       "5  Data Analyst Urgent Recruitment  divya interprises          0 to 4 Yrs\n",
       "6                   Data Analyst 1          merck ltd          1 to 3 Yrs\n",
       "7            Clinical Data Analyst      techno endura           0 to 1 Yr\n",
       "8         Data Analytics - Analyst           jpmorgan          0 to 4 Yrs\n",
       "9          Hiring For Data Analyst  divya interprises          0 to 4 Yrs"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"JOB TITLES\":job_titles,\"Company\": Company_Name, \"Experience Required\": Exp_Req})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2199958",
   "metadata": {},
   "source": [
    "Q2:Write a python program to scrape data for “Data Scientist” Job position in“Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Job title, Skills” field and enter “Bangalore” in “enter thelocation” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d09c56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "54609d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Designation = driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "Designation.send_keys(\"Data Scientist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7669afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Location = driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[2]/div/input\")\n",
    "Location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ca783b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8dbc46b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist Vacancy',\n",
       " 'Data Scientist Urgent Recruitment',\n",
       " 'Data Scientist- Bangalore',\n",
       " 'Data Scientist AI ML CV',\n",
       " 'Data Scientist-Bangalore',\n",
       " 'Data Scientist AI ML NLP',\n",
       " 'Phd Data Scientist',\n",
       " 'Hiring For Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Staff Data Scientist & Team Lead',\n",
       " 'Data scientist',\n",
       " 'Data Scientist Associate Sr - NLP',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data scientist Drivetrain',\n",
       " 'Data Architect',\n",
       " 'Data Scientist- Bangalore',\n",
       " 'Vice President - Data Analytics Scientist']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "\n",
    "titles = driver.find_elements(By.XPATH,\"//h2[@itemprop]\")\n",
    "for i in titles:\n",
    "    title = i.text\n",
    "    job_titles.append(title)\n",
    "job_titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5304881b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore\\n+14',\n",
       " 'Bangalore\\n+14',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+14',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+8',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+1',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+6',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore',\n",
       " 'Bangalore\\n+1']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = driver.find_elements(By.XPATH, '//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location:\n",
    "    loc = i.text\n",
    "    job_location.append(loc)\n",
    "job_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "872e771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['divya interprises',\n",
       " 'divya interprises',\n",
       " 'the fashion cosmo',\n",
       " 'bosch group',\n",
       " 'shiva hr services',\n",
       " 'bosch group',\n",
       " 'bosch group',\n",
       " 'divya interprises',\n",
       " 'racanaa energy solution private lim...',\n",
       " 'true caller',\n",
       " 'capgemini technology services india...',\n",
       " 'jpmorgan',\n",
       " 'siemens limited',\n",
       " 'mnr solutions pvt ltd',\n",
       " 'bosch group',\n",
       " 'mnr solutions pvt ltd',\n",
       " 'mercede',\n",
       " 'bosch group',\n",
       " 'the fashion cosmo',\n",
       " 'morgan stanley advantage services p...']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company = driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for i in company:\n",
    "    comp = i.text\n",
    "    company_name.append(comp)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7a4bd557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "12e873d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Titles</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Vacancy</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Urgent Recruitment</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist- Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>the fashion cosmo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist AI ML CV</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist-Bangalore</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>shiva hr services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist AI ML NLP</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phd Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>bosch group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>divya interprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>racanaa energy solution private lim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Staff Data Scientist &amp; Team Lead</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>true caller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Job Titles        Location  \\\n",
       "0             Data Scientist Vacancy  Bangalore\\n+14   \n",
       "1  Data Scientist Urgent Recruitment  Bangalore\\n+14   \n",
       "2          Data Scientist- Bangalore       Bangalore   \n",
       "3            Data Scientist AI ML CV       Bangalore   \n",
       "4           Data Scientist-Bangalore       Bangalore   \n",
       "5           Data Scientist AI ML NLP       Bangalore   \n",
       "6                 Phd Data Scientist       Bangalore   \n",
       "7          Hiring For Data Scientist  Bangalore\\n+14   \n",
       "8                     Data Scientist       Bangalore   \n",
       "9   Staff Data Scientist & Team Lead       Bangalore   \n",
       "\n",
       "                                  Company  \n",
       "0                       divya interprises  \n",
       "1                       divya interprises  \n",
       "2                       the fashion cosmo  \n",
       "3                             bosch group  \n",
       "4                       shiva hr services  \n",
       "5                             bosch group  \n",
       "6                             bosch group  \n",
       "7                       divya interprises  \n",
       "8  racanaa energy solution private lim...  \n",
       "9                             true caller  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Job Titles\": job_titles,\"Location\": job_location, \"Company\": company_name})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48d84a",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage \n",
    " You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the web page https://www.shine.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scrapeddata.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bc79c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.shine.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "29b55cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.XPATH,\"/html/body/div/div[5]/div/div[2]/div[2]/div/form/div/div[1]/ul/li[1]/div/input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "397c9927",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div/div[4]/div/div[2]/div[2]/div/form/div/div[2]/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e05411d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_filter = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div/ul/li[1]/button\")\n",
    "location_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7a6c2170",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_type = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[1]/input\")\n",
    "location_type.send_keys(\"Delhi/NCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4a873412",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_filter = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/ul/li[3]\")\n",
    "salary_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9f3e32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8ff941d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div[2]/div/div/div/div[4]/button[2]\")\n",
    "search2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5ca4e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div/ul/li[1]/button\")\n",
    "loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7852c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[1]/input\")\n",
    "loc1.send_keys(\"Delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "96e2430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "locc = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div[2]/div/div/div/div[3]/div/div/div/ul/li[2]/span/label\")\n",
    "locc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "82421fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div/div[1]/div/div[2]/div[2]/div/div/div/div[4]/button[2]\")\n",
    "results.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8038305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]')\n",
    "for i in title_tags:\n",
    "    title = i.text\n",
    "    job_titles.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "55f6ddfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delhi',\n",
       " 'Delhi',\n",
       " 'Delhi',\n",
       " 'Delhi',\n",
       " 'Delhi\\n+4',\n",
       " 'Delhi\\n+6',\n",
       " 'Delhi\\n+4',\n",
       " 'Delhi\\n+6',\n",
       " 'Delhi\\n+9',\n",
       " 'Delhi\\n+17',\n",
       " 'Delhi\\n+6',\n",
       " 'Delhi',\n",
       " 'Delhi',\n",
       " 'Delhi',\n",
       " 'Delhi\\n+6',\n",
       " 'Delhi\\n+6',\n",
       " 'Delhi',\n",
       " 'Delhi\\n+6',\n",
       " 'Delhi\\n+9',\n",
       " 'Delhi\\n+6']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for i in location_tags:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f24b739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags = driver.find_elements(By.XPATH,'//div[@class=\"jobCard_jobCard_cName__mYnow\"]')\n",
    "for i in company_tags:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "31dbdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience_tags = driver.find_elements(By.XPATH,'//div[@class=\" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for i in Experience_tags:\n",
    "    exp = i.text\n",
    "    experience_required.append(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ae4e4033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_titles),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9f0783a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job TItles</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>the fashion cosmo</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist-Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>shiva hr services</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>the fashion cosmo</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist- Delhi</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>the fashion cosmo</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Modeler</td>\n",
       "      <td>Delhi\\n+9</td>\n",
       "      <td>v-tech data outsourcing</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Biostatistician</td>\n",
       "      <td>Delhi\\n+17</td>\n",
       "      <td>national seeds corporation limited</td>\n",
       "      <td>1 to 6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Job TItles    Location                             Company  \\\n",
       "0  Data Scientist- Delhi       Delhi                   the fashion cosmo   \n",
       "1   Data Scientist-Delhi       Delhi                   shiva hr services   \n",
       "2  Data Scientist- Delhi       Delhi                   the fashion cosmo   \n",
       "3  Data Scientist- Delhi       Delhi                   the fashion cosmo   \n",
       "4         Data Scientist   Delhi\\n+4       acme services private limited   \n",
       "5         Data Scientist   Delhi\\n+6                     quiscon biotech   \n",
       "6         Data Scientist   Delhi\\n+4       acme services private limited   \n",
       "7  Clinical Data Analyst   Delhi\\n+6                       techno endura   \n",
       "8           Data Modeler   Delhi\\n+9             v-tech data outsourcing   \n",
       "9        Biostatistician  Delhi\\n+17  national seeds corporation limited   \n",
       "\n",
       "  Experience Required  \n",
       "0          0 to 3 Yrs  \n",
       "1          0 to 3 Yrs  \n",
       "2          0 to 3 Yrs  \n",
       "3          0 to 3 Yrs  \n",
       "4          3 to 5 Yrs  \n",
       "5           0 to 1 Yr  \n",
       "6          3 to 5 Yrs  \n",
       "7           0 to 1 Yr  \n",
       "8          0 to 2 Yrs  \n",
       "9          1 to 6 Yrs  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Job TItles\":job_titles,\"Location\":job_location,\"Company\":company_name,\"Experience Required\":experience_required})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcb379",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "6. Brand\n",
    "7. ProductDescription\n",
    "8. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search fieldwhere “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc9c79a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "                        \n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9c89f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/header/div[1]/div[2]/form/div/div/input\")\n",
    "search.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46dac207",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchh = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/header/div[1]/div[2]/form/div/button')\n",
    "searchh.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0af8050a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VINCENT CHASE',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'SRPM',\n",
       " 'GANSTA',\n",
       " 'ROADWAY',\n",
       " 'Fastrack',\n",
       " 'Elligator',\n",
       " 'john jacobs',\n",
       " 'ROYAL SON',\n",
       " 'Roadster',\n",
       " 'VINCENT CHASE',\n",
       " 'VINCENT CHASE',\n",
       " 'Roadster',\n",
       " 'ROADWAY',\n",
       " 'Rich Club',\n",
       " 'GANSTA',\n",
       " 'ROYAL SON',\n",
       " 'VINCENT CHASE',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'ROADWAY',\n",
       " 'ROYAL SON',\n",
       " 'ROYAL SON',\n",
       " 'Roadster',\n",
       " 'METRONAUT',\n",
       " 'Elligator',\n",
       " 'ROADWAY',\n",
       " 'ROYAL SON',\n",
       " 'Nicole Miller',\n",
       " 'PIRASO',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'PROVOGUE',\n",
       " 'VINCENT CHASE',\n",
       " 'Fastrack',\n",
       " 'PIRASO',\n",
       " 'Rich Club',\n",
       " 'VINCENT CHASE',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'ROYAL SON',\n",
       " 'Rich Club',\n",
       " 'DEIXELS',\n",
       " 'VINCENT CHASE',\n",
       " 'ROYAL SON',\n",
       " 'PIRASO',\n",
       " 'iCopertina',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Elligator',\n",
       " 'GUESS',\n",
       " 'Eyewearlabs',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'AISLIN',\n",
       " 'GUESS',\n",
       " 'METRONAUT',\n",
       " 'Elligator',\n",
       " 'GANSTA',\n",
       " 'PROVOGUE',\n",
       " 'NuVew',\n",
       " 'VINCENT CHASE',\n",
       " 'Eyenaks',\n",
       " 'Roadster',\n",
       " 'ROYAL SON',\n",
       " 'NuVew',\n",
       " 'Fastrack',\n",
       " 'VINCENT CHASE',\n",
       " 'Elligator',\n",
       " 'METRONAUT',\n",
       " 'ROYAL SON',\n",
       " 'VINCENT CHASE',\n",
       " 'PIRASO',\n",
       " 'Dressberry',\n",
       " 'ROYAL SON',\n",
       " 'ROYAL SON',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'NuVew',\n",
       " 'ROADWAY',\n",
       " 'VINCENT CHASE',\n",
       " 'ROYAL SON',\n",
       " 'ROYAL SON',\n",
       " 'Rich Club',\n",
       " 'ROYAL SON',\n",
       " 'ROYAL SON',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'PIRASO',\n",
       " 'Ray-Ban',\n",
       " 'ROYAL SON',\n",
       " 'ROYAL SON',\n",
       " 'VINCENT CHASE',\n",
       " 'VINCENT CHASE',\n",
       " 'Fastrack',\n",
       " 'john jacobs',\n",
       " 'VINCENT CHASE',\n",
       " 'Singco India',\n",
       " 'ROYAL SON',\n",
       " 'VINCENT CHASE',\n",
       " 'VINCENT CHASE',\n",
       " 'ROYAL SON',\n",
       " 'DEIXELS',\n",
       " 'PROVOGUE',\n",
       " 'Fastrack',\n",
       " 'Elligator',\n",
       " 'VINCENT CHASE',\n",
       " 'ROYAL SON',\n",
       " 'PIRASO',\n",
       " 'PETER JONES',\n",
       " 'Fastrack',\n",
       " 'Ray-Ban',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'VINCENT CHASE',\n",
       " 'Singco India',\n",
       " 'Eyewearlabs',\n",
       " 'john jacobs',\n",
       " 'GUESS',\n",
       " 'AISLIN',\n",
       " 'IRUS',\n",
       " 'VINCENT CHASE',\n",
       " 'OAKLEY',\n",
       " 'ROYAL SON',\n",
       " 'john jacobs',\n",
       " 'ROYAL SON',\n",
       " 'METRONAUT']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand = []\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start,end):\n",
    "    brand_tags = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand_tags:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    next_button = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1858e787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UV Protection, Gradient Retro Square Sunglasses (60)',\n",
       " 'UV Protection Retro Square Sunglasses (54)',\n",
       " 'UV Protection Oval Sunglasses (Free Size)',\n",
       " 'UV Protection, Gradient Butterfly, Wayfarer Sunglasses ...',\n",
       " 'Polarized Round Sunglasses (46)',\n",
       " 'UV Protection Clubmaster Sunglasses (Free Size)',\n",
       " 'UV Protection Wayfarer, Rectangular Sunglasses (61)',\n",
       " 'Toughened Glass Lens, UV Protection Aviator Sunglasses ...',\n",
       " 'UV Protection Cat-eye Sunglasses (55)',\n",
       " 'UV Protection, Gradient, Riding Glasses Over-sized Sung...',\n",
       " 'Gradient Rectangular Sunglasses (61)',\n",
       " 'UV Protection Cat-eye Sunglasses (56)',\n",
       " 'Polarized, UV Protection Rectangular Sunglasses (58)',\n",
       " 'Latch Beta Retro Square Sunglass',\n",
       " 'UV Protection Cat-eye Sunglasses (54)',\n",
       " 'UV Protection Rectangular Sunglasses (59)',\n",
       " 'UV Protection Cat-eye Sunglasses (56)',\n",
       " 'Riding Glasses, Night Vision Round, Spectacle Sunglass...',\n",
       " 'Gradient Butterfly Sunglasses (52)',\n",
       " 'Polarized, UV Protection Clubmaster Sunglasses (Free Si...',\n",
       " 'Polarized Rectangular Sunglasses (54)',\n",
       " 'Gradient Butterfly Sunglasses (58)',\n",
       " 'Polarized, UV Protection Wayfarer, Retro Square Sunglas...',\n",
       " 'Gradient Oval Sunglasses (53)',\n",
       " 'UV Protection, Gradient Clubmaster Sunglasses (Free Siz...',\n",
       " 'UV Protection, Gradient Wayfarer, Rectangular Sunglasse...',\n",
       " 'Gradient Aviator Sunglasses (62)',\n",
       " 'UV Protection Round Sunglasses (51)',\n",
       " 'Polarized, UV Protection Round Sunglasses (49)',\n",
       " 'Night Vision, Riding Glasses, UV Protection, Others Ret...',\n",
       " 'Gradient Aviator Sunglasses (63)',\n",
       " 'UV Protection, Gradient Cat-eye Sunglasses (51)',\n",
       " 'Gradient Retro Square Sunglasses (60)',\n",
       " 'Polarized, UV Protection Wayfarer Sunglasses (49)',\n",
       " 'UV Protection Wayfarer Sunglasses (61)',\n",
       " 'Mirrored Cat-eye Sunglasses (54)',\n",
       " 'UV Protection Retro Square Sunglasses (54)',\n",
       " 'UV Protection Retro Square Sunglasses (54)',\n",
       " 'Toughened Glass Lens, UV Protection Aviator Sunglasses ...',\n",
       " 'UV Protection, Gradient Wayfarer Sunglasses (53)',\n",
       " 'UV Protection, Gradient Retro Square Sunglasses (60)',\n",
       " 'UV Protection Retro Square Sunglasses (54)',\n",
       " 'UV Protection Oval Sunglasses (Free Size)',\n",
       " 'UV Protection, Gradient Butterfly, Wayfarer Sunglasses ...',\n",
       " 'Polarized Round Sunglasses (46)',\n",
       " 'UV Protection Clubmaster Sunglasses (Free Size)',\n",
       " 'UV Protection Wayfarer, Rectangular Sunglasses (61)',\n",
       " 'Toughened Glass Lens, UV Protection Aviator Sunglasses ...',\n",
       " 'UV Protection Cat-eye Sunglasses (55)',\n",
       " 'UV Protection, Gradient, Riding Glasses Over-sized Sung...',\n",
       " 'Gradient Rectangular Sunglasses (61)',\n",
       " 'UV Protection Cat-eye Sunglasses (56)',\n",
       " 'Polarized, UV Protection Rectangular Sunglasses (58)',\n",
       " 'Latch Beta Retro Square Sunglass',\n",
       " 'UV Protection Cat-eye Sunglasses (54)',\n",
       " 'UV Protection Rectangular Sunglasses (59)',\n",
       " 'UV Protection Cat-eye Sunglasses (56)',\n",
       " 'Riding Glasses, Night Vision Round, Spectacle Sunglass...',\n",
       " 'Gradient Butterfly Sunglasses (52)',\n",
       " 'Polarized, UV Protection Clubmaster Sunglasses (Free Si...',\n",
       " 'Polarized Rectangular Sunglasses (54)',\n",
       " 'Gradient Butterfly Sunglasses (58)',\n",
       " 'Polarized, UV Protection Wayfarer, Retro Square Sunglas...',\n",
       " 'Gradient Oval Sunglasses (53)',\n",
       " 'UV Protection, Gradient Clubmaster Sunglasses (Free Siz...',\n",
       " 'UV Protection, Gradient Wayfarer, Rectangular Sunglasse...',\n",
       " 'Gradient Aviator Sunglasses (62)',\n",
       " 'UV Protection Round Sunglasses (51)',\n",
       " 'Polarized, UV Protection Round Sunglasses (49)',\n",
       " 'Night Vision, Riding Glasses, UV Protection, Others Ret...',\n",
       " 'Gradient Aviator Sunglasses (63)',\n",
       " 'UV Protection, Gradient Cat-eye Sunglasses (51)',\n",
       " 'Gradient Retro Square Sunglasses (60)',\n",
       " 'Polarized, UV Protection Wayfarer Sunglasses (49)',\n",
       " 'UV Protection Wayfarer Sunglasses (61)',\n",
       " 'Mirrored Cat-eye Sunglasses (54)',\n",
       " 'UV Protection Retro Square Sunglasses (54)',\n",
       " 'UV Protection Retro Square Sunglasses (54)',\n",
       " 'Toughened Glass Lens, UV Protection Aviator Sunglasses ...',\n",
       " 'UV Protection, Gradient Wayfarer Sunglasses (53)',\n",
       " 'UV Protection, Gradient Retro Square Sunglasses (60)',\n",
       " 'UV Protection Retro Square Sunglasses (54)',\n",
       " 'UV Protection Oval Sunglasses (Free Size)',\n",
       " 'UV Protection, Gradient Butterfly, Wayfarer Sunglasses ...',\n",
       " 'Polarized Round Sunglasses (46)',\n",
       " 'UV Protection Clubmaster Sunglasses (Free Size)',\n",
       " 'UV Protection Wayfarer, Rectangular Sunglasses (61)',\n",
       " 'Toughened Glass Lens, UV Protection Aviator Sunglasses ...',\n",
       " 'UV Protection Cat-eye Sunglasses (55)',\n",
       " 'UV Protection, Gradient, Riding Glasses Over-sized Sung...',\n",
       " 'Gradient Rectangular Sunglasses (61)',\n",
       " 'UV Protection Cat-eye Sunglasses (56)',\n",
       " 'Polarized, UV Protection Rectangular Sunglasses (58)',\n",
       " 'Latch Beta Retro Square Sunglass',\n",
       " 'UV Protection Cat-eye Sunglasses (54)',\n",
       " 'UV Protection Rectangular Sunglasses (59)',\n",
       " 'UV Protection Cat-eye Sunglasses (56)',\n",
       " 'Riding Glasses, Night Vision Round, Spectacle Sunglass...',\n",
       " 'Gradient Butterfly Sunglasses (52)',\n",
       " 'Polarized, UV Protection Clubmaster Sunglasses (Free Si...',\n",
       " 'Polarized Rectangular Sunglasses (54)',\n",
       " 'Gradient Butterfly Sunglasses (58)',\n",
       " 'Polarized, UV Protection Wayfarer, Retro Square Sunglas...',\n",
       " 'Gradient Oval Sunglasses (53)',\n",
       " 'UV Protection, Gradient Clubmaster Sunglasses (Free Siz...',\n",
       " 'UV Protection, Gradient Wayfarer, Rectangular Sunglasse...',\n",
       " 'Gradient Aviator Sunglasses (62)',\n",
       " 'UV Protection Round Sunglasses (51)',\n",
       " 'Polarized, UV Protection Round Sunglasses (49)',\n",
       " 'Night Vision, Riding Glasses, UV Protection, Others Ret...',\n",
       " 'Gradient Aviator Sunglasses (63)',\n",
       " 'UV Protection, Gradient Cat-eye Sunglasses (51)',\n",
       " 'Gradient Retro Square Sunglasses (60)',\n",
       " 'Polarized, UV Protection Wayfarer Sunglasses (49)',\n",
       " 'UV Protection Wayfarer Sunglasses (61)',\n",
       " 'Mirrored Cat-eye Sunglasses (54)',\n",
       " 'UV Protection Retro Square Sunglasses (54)',\n",
       " 'UV Protection Retro Square Sunglasses (54)',\n",
       " 'Toughened Glass Lens, UV Protection Aviator Sunglasses ...',\n",
       " 'UV Protection, Gradient Wayfarer Sunglasses (53)']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = []\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start,end):\n",
    "    desc = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in desc:\n",
    "        description.append(i.text)\n",
    "    next_button = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c95da6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d66d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = []\n",
    "\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start,end):\n",
    "    price_tags = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in price_tags:\n",
    "        price.append(i.text)\n",
    "    next_button = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf100f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = []\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start,end):\n",
    "    discount_tags = driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in discount_tags:\n",
    "        discount.append(i.text)\n",
    "    next_button = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f3b12ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(description),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98afb7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹954</td>\n",
       "      <td>13% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "      <td>₹909</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Oval Sunglasses (Free Size)</td>\n",
       "      <td>₹149</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Gradient Butterfly, Wayfarer Su...</td>\n",
       "      <td>₹79</td>\n",
       "      <td>93% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>Polarized Round Sunglasses (46)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (59)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (56)</td>\n",
       "      <td>₹580</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PROVOGUE</td>\n",
       "      <td>Riding Glasses, Night Vision Round, Spectacle ...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient Butterfly Sunglasses (52)</td>\n",
       "      <td>₹714</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>Polarized, UV Protection Clubmaster Sunglasses...</td>\n",
       "      <td>₹169</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                        Description Price  \\\n",
       "0    VINCENT CHASE  UV Protection, Gradient Retro Square Sunglasse...  ₹954   \n",
       "1   ROZZETTA CRAFT         UV Protection Retro Square Sunglasses (54)  ₹909   \n",
       "2             SRPM          UV Protection Oval Sunglasses (Free Size)  ₹149   \n",
       "3           GANSTA  UV Protection, Gradient Butterfly, Wayfarer Su...   ₹79   \n",
       "4          ROADWAY                    Polarized Round Sunglasses (46)  ₹199   \n",
       "..             ...                                                ...   ...   \n",
       "95       ROYAL SON          UV Protection Rectangular Sunglasses (59)  ₹599   \n",
       "96         DEIXELS              UV Protection Cat-eye Sunglasses (56)  ₹580   \n",
       "97        PROVOGUE  Riding Glasses, Night Vision Round, Spectacle ...  ₹399   \n",
       "98        Fastrack                 Gradient Butterfly Sunglasses (52)  ₹714   \n",
       "99       Elligator  Polarized, UV Protection Clubmaster Sunglasses...  ₹169   \n",
       "\n",
       "   Discount in %  \n",
       "0        13% off  \n",
       "1        59% off  \n",
       "2        88% off  \n",
       "3        93% off  \n",
       "4        84% off  \n",
       "..           ...  \n",
       "95       76% off  \n",
       "96       62% off  \n",
       "97       80% off  \n",
       "98       35% off  \n",
       "99       25% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Brand\":brand,\"Description\":description,\"Price\":price,\"Discount in %\": discount})\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a8f19",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "place=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2bb7de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYHWAXCG&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "675020cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating= []\n",
    "reviews= []\n",
    "brief = []\n",
    "start=0\n",
    "end=10\n",
    "for page in range(start,end):\n",
    "    stars = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in stars[0:100]:\n",
    "         rating.append(i.text)\n",
    "    review_title = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review_title:\n",
    "        reviews.append(i.text)\n",
    "    brief_review = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in brief_review:\n",
    "        brief.append(i.text)\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "next_button = driver.find_element(By.XPATH,'//nav[@class=\"yFHi8N\"]/a[11]')\n",
    "next_button.click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e2f4920a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Star Ratings</th>\n",
       "      <th>Review title</th>\n",
       "      <th>Brief Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Awesome Battery Life...Camera clarity is too g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Photos super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money 😍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Go for iPhone 11 , if confused between iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Super🔥 and good performance 👌❤️</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Star Ratings         Review title  \\\n",
       "0             5   Highly recommended   \n",
       "1             5     Perfect product!   \n",
       "2             5  Best in the market!   \n",
       "3             5       Classy product   \n",
       "4             5    Worth every penny   \n",
       "..          ...                  ...   \n",
       "95            5             Terrific   \n",
       "96            5    Terrific purchase   \n",
       "97            5            Wonderful   \n",
       "98            5            Must buy!   \n",
       "99            5            Fabulous!   \n",
       "\n",
       "                                         Brief Review  \n",
       "0   Awesome Battery Life...Camera clarity is too g...  \n",
       "1                                        Photos super  \n",
       "2                                         Good Camera  \n",
       "3   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "4   Feeling awesome after getting the delivery of ...  \n",
       "..                                                ...  \n",
       "95                                     Very very good  \n",
       "96                                  Value for money 😍  \n",
       "97                             This is amazing at all  \n",
       "98  Go for iPhone 11 , if confused between iPhone ...  \n",
       "99                    Super🔥 and good performance 👌❤️  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Star Ratings\":rating,\"Review title\":reviews,\"Brief Review\":brief})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed4253",
   "metadata": {},
   "source": [
    "Q6: Scrape data forfirst 100 sneakers you find whenyou visit flipkart.com and search for “sneakers” inthe\n",
    "search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b45a9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c4ec2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tab = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "search_tab.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9115cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/header/div[1]/div[2]/form/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7bfb08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Description = []\n",
    "Price = []\n",
    "start = 0\n",
    "end = 3\n",
    "for page in range(start,end):\n",
    "    brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:\n",
    "        Brand.append(i.text)\n",
    "        \n",
    "    pr_desc = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in pr_desc:\n",
    "        Description.append(i.text)\n",
    "        \n",
    "    prices = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in prices:\n",
    "        Price.append(i.text)\n",
    "        \n",
    "    next_button = driver.find_element(By.XPATH,'//nav[@class=\"yFHi8N\"]/a[11]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1410dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 119 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Description),len(Price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e2d2e",
   "metadata": {},
   "source": [
    "Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then\n",
    "set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "    After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "50cf1933",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c3692f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "65f98123",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_icon = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "12e60c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_filter = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[6]/span[12]/li/span/a/div/label/i')\n",
    "CPU_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "53ffeff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles = []\n",
    "Ratings = []\n",
    "Price = []\n",
    "\n",
    "Title_tags = driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in Title_tags[0:10]:\n",
    "    Titles.append(i.text)\n",
    "    \n",
    "Ratings_tags = driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]')\n",
    "for i in Ratings_tags[0:10]:\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "Price_Tags = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in Price_Tags[0:10]:\n",
    "    Price.append(i.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "210b448d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Titles),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8839f18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Titles</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...</td>\n",
       "      <td>20</td>\n",
       "      <td>63,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...</td>\n",
       "      <td>23</td>\n",
       "      <td>49,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...</td>\n",
       "      <td>330</td>\n",
       "      <td>60,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Inspiron 5430 Laptop, Intel Core i7-1360P...</td>\n",
       "      <td>46</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...</td>\n",
       "      <td>52</td>\n",
       "      <td>68,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15, 15.6-inch (39.62 cms) FHD...</td>\n",
       "      <td>86</td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i7 11th Gen 1...</td>\n",
       "      <td>59</td>\n",
       "      <td>52,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Samsung Galaxy Book3 Core i7 13th Gen 1355U - ...</td>\n",
       "      <td>28</td>\n",
       "      <td>84,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...</td>\n",
       "      <td>150</td>\n",
       "      <td>57,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acer Predator Helios Neo 16 Gaming Laptop 13th...</td>\n",
       "      <td>124</td>\n",
       "      <td>1,29,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Laptop Titles Ratings     Price\n",
       "0  HP Laptop 15s, 12th Gen Intel Core i7-1255U, 1...      20    63,990\n",
       "1  MSI Modern 14, Intel 12th Gen. i7-1255U, 36CM ...      23    49,990\n",
       "2  ASUS Vivobook 15, Intel Core i7-12650H 12th Ge...     330    60,990\n",
       "3  Dell Inspiron 5430 Laptop, Intel Core i7-1360P...      46    84,990\n",
       "4  ASUS TUF Gaming F15, 15.6\"(39.62 cms) FHD 144H...      52    68,990\n",
       "5  ASUS TUF Gaming F15, 15.6-inch (39.62 cms) FHD...      86    85,990\n",
       "6  Lenovo IdeaPad Slim 3 Intel Core i7 11th Gen 1...      59    52,990\n",
       "7  Samsung Galaxy Book3 Core i7 13th Gen 1355U - ...      28    84,390\n",
       "8  MSI GF63 Thin, Intel Core i7-11800H, 40CM FHD ...     150    57,990\n",
       "9  Acer Predator Helios Neo 16 Gaming Laptop 13th...     124  1,29,990"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Laptop Titles\":Titles,\"Ratings\":Ratings,\"Price\":Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8c647",
   "metadata": {},
   "source": [
    "Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9c0c118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.azquotes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "25498289",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_quotes = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f853f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quotes = []\n",
    "Authors = []\n",
    "Type_Of_Quotes = []\n",
    "start = 0\n",
    "end = 10\n",
    "for page in range(start,end):\n",
    "    Quote = driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for i in Quote:\n",
    "        Quotes.append(i.text)\n",
    "        \n",
    "    Author = driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for i in Author:\n",
    "        Authors.append(i.text)\n",
    "        \n",
    "    Type = driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for i in Type:\n",
    "        Type_Of_Quotes.append(i.text)\n",
    "        \n",
    "    next_button = driver.find_element(By.XPATH,'//div[@class=\"pager\"]/li[12]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a8a99611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(Quotes),len(Authors),len(Type_Of_Quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "598f20c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top Quotes</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Type Of The Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Top Quotes             Authors  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                            Type Of The Quote  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Top Quotes\":Quotes,\"Authors\":Authors,\"Type Of The Quote\":Type_Of_Quotes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042df10d",
   "metadata": {},
   "source": [
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead,\n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79a58e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f655a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabs = driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div/div/div[3]/ul/li[6]/a')\n",
    "Tabs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47c90571",
   "metadata": {},
   "outputs": [],
   "source": [
    "List = driver.find_element(By.XPATH,'/html/body/div[2]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "List.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eef5bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaders = []\n",
    "table = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[3]')\n",
    "Rows = table.find_elements(By.TAG_NAME,'tr')\n",
    "for row in Rows:\n",
    "    columns = table.find_elements(By.TAG_NAME,'td')\n",
    "    if len(columns)==4:\n",
    "        Names = columns[0].text\n",
    "        Born_Dead = columns[1].text\n",
    "        Terms = columns[2].text\n",
    "        Remarks = columns[3].text\n",
    "        leaders.append((Names,Born_Dead,Terms,Remarks))\n",
    "        \n",
    "leaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b22f67af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Born-Dead, Term of Office, Remarks]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(leaders, columns=['Name', 'Born-Dead', 'Term of Office', 'Remarks'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59cd6d",
   "metadata": {},
   "source": [
    "Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e.\n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d00da932",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a4777e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar = driver.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/button')\n",
    "search_bar.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23b4650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search2 = driver.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "search2.send_keys(\"50 most expensive cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "528f8db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search3 = driver.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/button[1]')\n",
    "search3.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf1797",
   "metadata": {},
   "source": [
    "search results = The content you are looking for doesn't exist yet. To continue, try other site section.\n",
    "\n",
    "Sorry to disappoint you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
